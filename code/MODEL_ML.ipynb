{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and installing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: impyute in c:\\users\\joe\\anaconda3\\lib\\site-packages (0.0.8)\n",
      "Requirement already satisfied: scipy in c:\\users\\joe\\anaconda3\\lib\\site-packages (from impyute) (1.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\joe\\anaconda3\\lib\\site-packages (from impyute) (1.18.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\joe\\anaconda3\\lib\\site-packages (from impyute) (0.23.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\joe\\anaconda3\\lib\\site-packages (from scikit-learn->impyute) (0.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\joe\\anaconda3\\lib\\site-packages (from scikit-learn->impyute) (2.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Joe\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# installing missingpy for missforest and impyute for mice\n",
    "!pip install impyute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: missingpy in c:\\users\\joe\\anaconda3\\lib\\site-packages (0.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Joe\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install missingpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joe\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# import the necessary libraries\n",
    "# basic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# imputation and resampling\n",
    "from impute_functions import *\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "\n",
    "# models\n",
    "from catboost import CatBoostClassifier as catboost\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier as xgb\n",
    "from sklearn.ensemble import AdaBoostClassifier as adaboost\n",
    "from lightgbm import LGBMClassifier as lightgbm\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# misc.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_validate\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from feature_engineer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning suppression\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "names = (['ID', 'Expense', 'Income', 'Loan type', 'Occupation type', \n",
    "         'Age', 'Score1', 'Score2', 'Score3', 'Score4', 'Score5'])\n",
    "\n",
    "X = pd.read_csv('dataset/train_x.csv', index_col = 'ID', names = names, skiprows = 1)\n",
    "y = pd.read_csv('dataset/train_y.csv', index_col = 'ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we encode some categoricals into labels\n",
    "X = ManualEncoder(X)\n",
    "X.to_csv('Encoded_X.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ready access, we save some temporary files\n",
    "X = pd.read_csv('Encoded_X.csv', index_col = 'ID')\n",
    "y = pd.read_csv('dataset/train_y.csv', index_col = 'ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest imputing the data ([2,3,4] are the column indices of the categorical features)\n",
    "X_rf = rf_imputer(X, [2,3,4])\n",
    "X_rf = pd.DataFrame(X_rf, columns=X.columns).set_index(np.arange(1,80001))\n",
    "X_rf.index.name = 'ID'\n",
    "X_rf.to_csv('RF_imputed_X.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expense</th>\n",
       "      <th>Income</th>\n",
       "      <th>Loan type</th>\n",
       "      <th>Occupation type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Score1</th>\n",
       "      <th>Score2</th>\n",
       "      <th>Score3</th>\n",
       "      <th>Score4</th>\n",
       "      <th>Score5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1830.943788</td>\n",
       "      <td>14767.28013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016885</td>\n",
       "      <td>205.196182</td>\n",
       "      <td>22.521523</td>\n",
       "      <td>600.911200</td>\n",
       "      <td>3464.613291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1645.302546</td>\n",
       "      <td>15272.26775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.240375</td>\n",
       "      <td>194.266317</td>\n",
       "      <td>5.349117</td>\n",
       "      <td>600.888816</td>\n",
       "      <td>3374.921455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1555.026392</td>\n",
       "      <td>17482.49734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213921</td>\n",
       "      <td>183.529871</td>\n",
       "      <td>-1.054954</td>\n",
       "      <td>598.596944</td>\n",
       "      <td>3331.304886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1681.233164</td>\n",
       "      <td>16257.66493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303909</td>\n",
       "      <td>191.228965</td>\n",
       "      <td>6.971750</td>\n",
       "      <td>602.447203</td>\n",
       "      <td>3392.275849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1777.648916</td>\n",
       "      <td>16316.29914</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.300104</td>\n",
       "      <td>224.074728</td>\n",
       "      <td>11.218489</td>\n",
       "      <td>605.947340</td>\n",
       "      <td>3438.864083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>1470.317116</td>\n",
       "      <td>16659.49663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208757</td>\n",
       "      <td>172.526308</td>\n",
       "      <td>-5.332184</td>\n",
       "      <td>596.648261</td>\n",
       "      <td>3290.377932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>1923.617480</td>\n",
       "      <td>14910.36890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201837</td>\n",
       "      <td>186.252458</td>\n",
       "      <td>15.425841</td>\n",
       "      <td>600.855069</td>\n",
       "      <td>3509.388221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>1711.147154</td>\n",
       "      <td>15962.25945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.226396</td>\n",
       "      <td>196.098150</td>\n",
       "      <td>8.161353</td>\n",
       "      <td>601.360722</td>\n",
       "      <td>3406.734018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>1673.822523</td>\n",
       "      <td>15525.27413</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101090</td>\n",
       "      <td>186.390184</td>\n",
       "      <td>3.381393</td>\n",
       "      <td>596.750750</td>\n",
       "      <td>3388.700770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80000</th>\n",
       "      <td>1486.290579</td>\n",
       "      <td>16207.20250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187832</td>\n",
       "      <td>182.131337</td>\n",
       "      <td>-4.069284</td>\n",
       "      <td>597.251640</td>\n",
       "      <td>3298.102630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Expense       Income  Loan type  Occupation type  Age    Score1  \\\n",
       "ID                                                                           \n",
       "1      1830.943788  14767.28013        1.0              1.0  1.0  0.016885   \n",
       "2      1645.302546  15272.26775        1.0              1.0  0.0  0.240375   \n",
       "3      1555.026392  17482.49734        0.0              1.0  0.0  0.213921   \n",
       "4      1681.233164  16257.66493        0.0              1.0  0.0  0.303909   \n",
       "5      1777.648916  16316.29914        1.0              0.0  1.0  0.300104   \n",
       "...            ...          ...        ...              ...  ...       ...   \n",
       "79996  1470.317116  16659.49663        0.0              2.0  0.0  0.208757   \n",
       "79997  1923.617480  14910.36890        1.0              1.0  0.0  0.201837   \n",
       "79998  1711.147154  15962.25945        0.0              1.0  1.0  0.226396   \n",
       "79999  1673.822523  15525.27413        1.0              2.0  0.0  0.101090   \n",
       "80000  1486.290579  16207.20250        0.0              2.0  0.0  0.187832   \n",
       "\n",
       "           Score2     Score3      Score4       Score5  \n",
       "ID                                                     \n",
       "1      205.196182  22.521523  600.911200  3464.613291  \n",
       "2      194.266317   5.349117  600.888816  3374.921455  \n",
       "3      183.529871  -1.054954  598.596944  3331.304886  \n",
       "4      191.228965   6.971750  602.447203  3392.275849  \n",
       "5      224.074728  11.218489  605.947340  3438.864083  \n",
       "...           ...        ...         ...          ...  \n",
       "79996  172.526308  -5.332184  596.648261  3290.377932  \n",
       "79997  186.252458  15.425841  600.855069  3509.388221  \n",
       "79998  196.098150   8.161353  601.360722  3406.734018  \n",
       "79999  186.390184   3.381393  596.750750  3388.700770  \n",
       "80000  182.131337  -4.069284  597.251640  3298.102630  \n",
       "\n",
       "[80000 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for easy access\n",
    "X = pd.read_csv('RF_imputed_X.csv', index_col = 'ID')\n",
    "y = pd.read_csv('dataset/train_y.csv', index_col = 'ID')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic clean deletes rows with nan y and scales the columns from the passed list (all non categorical)\n",
    "non_cat_cols_X = ['Expense','Income','Score1','Score2','Score3','Score4','Score5']\n",
    "\n",
    "# calling the basic clean from impute_functions.py\n",
    "X, y = basic_clean(X, y, non_cat_cols_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the index column name\n",
    "X.index.name = 'ID'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation prior to feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80:20 model split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60877 entries, 44382 to 15795\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Expense          60877 non-null  float64\n",
      " 1   Income           60877 non-null  float64\n",
      " 2   Loan type        60877 non-null  float64\n",
      " 3   Occupation type  60877 non-null  float64\n",
      " 4   Age              60877 non-null  float64\n",
      " 5   Score1           60877 non-null  float64\n",
      " 6   Score2           60877 non-null  float64\n",
      " 7   Score3           60877 non-null  float64\n",
      " 8   Score4           60877 non-null  float64\n",
      " 9   Score5           60877 non-null  float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 5.1 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data types are all float. The parameters income, loan_type, Occupation type and Age are in reality categorical but since all but Occupation type are already one-hot encoded, we may consider them as integers/floats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    56812\n",
       "1.0     4065\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let us look at the data imbalance\n",
    "y_train['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must correct this huge imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use smote categorical oversampling\n",
    "oversampler = SMOTENC(random_state= 42, categorical_features=[2,3,4], sampling_strategy=2/3)\n",
    "X_train, y_train = oversampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting the ID as it is removed during oversampling\n",
    "X_train.index.name = 'ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that creates dummy columns for the occupation type category that has three categories\n",
    "X_train, y_train = dummy_creator(X_train, y_train)\n",
    "X_test, y_test = dummy_creator(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94686 entries, 0 to 94685\n",
      "Data columns (total 11 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Expense    94686 non-null  float64\n",
      " 1   Income     94686 non-null  float64\n",
      " 2   Loan type  94686 non-null  float64\n",
      " 3   Age        94686 non-null  float64\n",
      " 4   Score1     94686 non-null  float64\n",
      " 5   Score2     94686 non-null  float64\n",
      " 6   Score3     94686 non-null  float64\n",
      " 7   Score4     94686 non-null  float64\n",
      " 8   Score5     94686 non-null  float64\n",
      " 9   Y          94686 non-null  uint8  \n",
      " 10  Z          94686 non-null  uint8  \n",
      "dtypes: float64(9), uint8(2)\n",
      "memory usage: 6.7 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Model Evaluation (pre-feature engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A data table to store the model performances\n",
    "results = pd.DataFrame(columns = ['Model name','Feature_Engineered_data(Y/N)','F1-score(weighted)','Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We try the train data on a variety of models; catboost, extra-trees, xgboost, adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expense</th>\n",
       "      <th>Income</th>\n",
       "      <th>Loan type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Score1</th>\n",
       "      <th>Score2</th>\n",
       "      <th>Score3</th>\n",
       "      <th>Score4</th>\n",
       "      <th>Score5</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.247941</td>\n",
       "      <td>-1.359844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.144554</td>\n",
       "      <td>-0.903721</td>\n",
       "      <td>-1.115572</td>\n",
       "      <td>-1.056263</td>\n",
       "      <td>-2.247964</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029614</td>\n",
       "      <td>0.924177</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.643451</td>\n",
       "      <td>0.909074</td>\n",
       "      <td>-0.114357</td>\n",
       "      <td>0.950666</td>\n",
       "      <td>0.029617</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.548192</td>\n",
       "      <td>-1.079564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.354195</td>\n",
       "      <td>-0.646945</td>\n",
       "      <td>0.414402</td>\n",
       "      <td>-0.492169</td>\n",
       "      <td>-0.548195</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.053660</td>\n",
       "      <td>0.110537</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.687367</td>\n",
       "      <td>0.226460</td>\n",
       "      <td>-0.807300</td>\n",
       "      <td>0.262248</td>\n",
       "      <td>-1.053669</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.063227</td>\n",
       "      <td>-1.374961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.598246</td>\n",
       "      <td>0.109126</td>\n",
       "      <td>2.085999</td>\n",
       "      <td>0.062605</td>\n",
       "      <td>1.063222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94681</th>\n",
       "      <td>-0.299023</td>\n",
       "      <td>-0.979383</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.310431</td>\n",
       "      <td>-0.206143</td>\n",
       "      <td>-1.718584</td>\n",
       "      <td>-0.342753</td>\n",
       "      <td>-0.299024</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94682</th>\n",
       "      <td>0.615423</td>\n",
       "      <td>1.336259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.896311</td>\n",
       "      <td>1.201401</td>\n",
       "      <td>0.108299</td>\n",
       "      <td>-0.501115</td>\n",
       "      <td>0.615429</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94683</th>\n",
       "      <td>0.318102</td>\n",
       "      <td>1.619585</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.093309</td>\n",
       "      <td>1.039731</td>\n",
       "      <td>0.027950</td>\n",
       "      <td>-0.715338</td>\n",
       "      <td>0.318108</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94684</th>\n",
       "      <td>0.166797</td>\n",
       "      <td>1.198599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.123428</td>\n",
       "      <td>-0.261709</td>\n",
       "      <td>-0.282120</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>0.166801</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94685</th>\n",
       "      <td>0.206231</td>\n",
       "      <td>-1.179200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.591123</td>\n",
       "      <td>-0.586139</td>\n",
       "      <td>0.838308</td>\n",
       "      <td>-0.280588</td>\n",
       "      <td>0.206236</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94686 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Expense    Income  Loan type  Age    Score1    Score2    Score3  \\\n",
       "ID                                                                        \n",
       "0     -2.247941 -1.359844        0.0  0.0 -0.144554 -0.903721 -1.115572   \n",
       "1      0.029614  0.924177        1.0  1.0  0.643451  0.909074 -0.114357   \n",
       "2     -0.548192 -1.079564        0.0  0.0 -0.354195 -0.646945  0.414402   \n",
       "3     -1.053660  0.110537        1.0  1.0  0.687367  0.226460 -0.807300   \n",
       "4      1.063227 -1.374961        0.0  1.0 -1.598246  0.109126  2.085999   \n",
       "...         ...       ...        ...  ...       ...       ...       ...   \n",
       "94681 -0.299023 -0.979383        1.0  0.0  1.310431 -0.206143 -1.718584   \n",
       "94682  0.615423  1.336259        1.0  1.0 -1.896311  1.201401  0.108299   \n",
       "94683  0.318102  1.619585        1.0  1.0 -2.093309  1.039731  0.027950   \n",
       "94684  0.166797  1.198599        0.0  0.0 -0.123428 -0.261709 -0.282120   \n",
       "94685  0.206231 -1.179200        0.0  0.0 -0.591123 -0.586139  0.838308   \n",
       "\n",
       "         Score4    Score5  Y  Z  \n",
       "ID                               \n",
       "0     -1.056263 -2.247964  0  1  \n",
       "1      0.950666  0.029617  0  0  \n",
       "2     -0.492169 -0.548195  1  0  \n",
       "3      0.262248 -1.053669  1  0  \n",
       "4      0.062605  1.063222  0  0  \n",
       "...         ...       ... .. ..  \n",
       "94681 -0.342753 -0.299024  0  1  \n",
       "94682 -0.501115  0.615429  1  0  \n",
       "94683 -0.715338  0.318108  1  0  \n",
       "94684 -0.375612  0.166801  1  0  \n",
       "94685 -0.280588  0.206236  1  0  \n",
       "\n",
       "[94686 rows x 11 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99     14252\n",
      "         1.0       0.87      0.86      0.86       968\n",
      "\n",
      "    accuracy                           0.98     15220\n",
      "   macro avg       0.93      0.92      0.93     15220\n",
      "weighted avg       0.98      0.98      0.98     15220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extra trees Classifier\n",
    "model = ExtraTreesClassifier()\n",
    "# Scoring\n",
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_test)\n",
    "print(classification_report(y_test, preds))\n",
    "results = results.append({'Model name':'Extra Trees',\n",
    "                          'Feature_Engineered_data(Y/N)':'N',\n",
    "                          'F1-score(weighted)':f1_score(y_test, preds, average = 'weighted'),\n",
    "                          'Accuracy':accuracy_score(y_test, preds)},\n",
    "                        ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99     14252\n",
      "         1.0       0.86      0.88      0.87       968\n",
      "\n",
      "    accuracy                           0.98     15220\n",
      "   macro avg       0.93      0.94      0.93     15220\n",
      "weighted avg       0.98      0.98      0.98     15220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# catboost classifier\n",
    "cat_params = {'depth': 10}\n",
    "model = catboost(verbose = False, **cat_params)\n",
    "\n",
    "# Scoring\n",
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_test)\n",
    "print(classification_report(y_test, preds))\n",
    "results = results.append({'Model name':'Catboost',\n",
    "                          'Feature_Engineered_data(Y/N)':'N',\n",
    "                          'F1-score(weighted)':f1_score(y_test, preds, average = 'weighted'),\n",
    "                          'Accuracy':accuracy_score(y_test, preds)},\n",
    "                        ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the 'class 0' scores are nearly the same, the extra trees classifier improves the precision for 'class 1' at the cost of lowered recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99     14252\n",
      "         1.0       0.88      0.86      0.87       968\n",
      "\n",
      "    accuracy                           0.98     15220\n",
      "   macro avg       0.93      0.92      0.93     15220\n",
      "weighted avg       0.98      0.98      0.98     15220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# trying to Removing Score5 as concluded in the feature enginnering report\n",
    "model = ExtraTreesClassifier()\n",
    "\n",
    "model.fit(X_train.drop('Score5', axis =1),y_train)\n",
    "preds = model.predict(X_test.drop('Score5', axis= 1))\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "# this lack of change verifies that feature 'score5' can be dropped as per the feature engineering result without any change in results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99     14252\n",
      "         1.0       0.85      0.87      0.86       968\n",
      "\n",
      "    accuracy                           0.98     15220\n",
      "   macro avg       0.92      0.93      0.92     15220\n",
      "weighted avg       0.98      0.98      0.98     15220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# xgboost classifier\n",
    "xgb_params = {'max_depth': 17, 'min_child_weight': 1}\n",
    "model = xgb(**xgb_params)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_test)\n",
    "print(classification_report(y_test, preds))\n",
    "results = results.append({'Model name':'XGBoost',\n",
    "                          'Feature_Engineered_data(Y/N)':'N',\n",
    "                          'F1-score(weighted)':f1_score(y_test, preds, average = 'weighted'),\n",
    "                          'Accuracy':accuracy_score(y_test, preds)},\n",
    "                        ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.92      0.95     14252\n",
      "         1.0       0.42      0.85      0.56       968\n",
      "\n",
      "    accuracy                           0.92     15220\n",
      "   macro avg       0.71      0.88      0.76     15220\n",
      "weighted avg       0.95      0.92      0.93     15220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# adaboost classifier\n",
    "model = adaboost()\n",
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_test)\n",
    "print('Adaboost Classifier:')\n",
    "print(classification_report(y_test, preds))\n",
    "results = results.append({'Model name':'Adaboost',\n",
    "                          'Feature_Engineered_data(Y/N)':'N',\n",
    "                          'F1-score(weighted)':f1_score(y_test, preds, average = 'weighted'),\n",
    "                          'Accuracy':accuracy_score(y_test, preds)},\n",
    "                        ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Catboost classifier gives the best results in terms of macro and weighted F1-scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation (after feature Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# we use smote categorical oversampling\n",
    "oversampler = SMOTENC(random_state= 42, categorical_features=[2,3,4], sampling_strategy=2/3)\n",
    "X_train, y_train = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# reset index name as smote removes the index name\n",
    "X_train.index.name = 'ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the feature engineering function from feature_engineer.py on train and test data\n",
    "X_train, X_train_bins = feature_engineer(X_train.reset_index(), False)\n",
    "X_test, X_test_bins = feature_engineer(X_test.reset_index(), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that creates dummy columns for the occupation type category that has three categories\n",
    "X_train, y_train = dummy_creator(X_train, y_train)\n",
    "X_test, y_test = dummy_creator(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This conversion is done so that catboost may consider these features \n",
    "# as categorical features as they are already one-hot encoded (two categories)\n",
    "X_train['Loan type'] = X_train['Loan type'].astype(int)\n",
    "X_train.Age = X_train.Age.astype(int)\n",
    "X_train['Age X Loan type'] = X_train['Age X Loan type'].astype(int)\n",
    "\n",
    "X_test['Loan type'] = X_test['Loan type'].astype(int)\n",
    "X_test.Age = X_test.Age.astype(int)\n",
    "X_test['Age X Loan type'] = X_test['Age X Loan type'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trying out various Classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.990     0.991     0.990     14252\n",
      "         1.0      0.867     0.847     0.857       968\n",
      "\n",
      "    accuracy                          0.982     15220\n",
      "   macro avg      0.928     0.919     0.924     15220\n",
      "weighted avg      0.982     0.982     0.982     15220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extra trees Classifier\n",
    "model = ExtraTreesClassifier()\n",
    "\n",
    "#fit the model and predict\n",
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_test)\n",
    "print('Extra Trees Classifier:')\n",
    "\n",
    "#shows us the classification report\n",
    "print(classification_report(y_test, preds, digits= 3))\n",
    "\n",
    "# add the data to the results dataframe\n",
    "results = results.append({'Model name':'Extra Trees',\n",
    "                          'Feature_Engineered_data(Y/N)':'Y',\n",
    "                          'F1-score(weighted)':f1_score(y_test, preds, average = 'weighted'),\n",
    "                          'Accuracy':accuracy_score(y_test, preds)},\n",
    "                        ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catboost Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.992     0.990     0.991     14252\n",
      "         1.0      0.860     0.879     0.869       968\n",
      "\n",
      "    accuracy                          0.983     15220\n",
      "   macro avg      0.926     0.935     0.930     15220\n",
      "weighted avg      0.983     0.983     0.983     15220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Catboost Classifier\n",
    "cat_params = {'verbose': False, 'depth': 10}\n",
    "model = catboost(**cat_params)\n",
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_test)\n",
    "print('Catboost Classifier:')\n",
    "print(classification_report(y_test, preds, digits= 3))\n",
    "results = results.append({'Model name':'Catboost',\n",
    "                          'Feature_Engineered_data(Y/N)':'Y',\n",
    "                          'F1-score(weighted)':f1_score(y_test, preds, average = 'weighted'),\n",
    "                          'Accuracy':accuracy_score(y_test, preds)},\n",
    "                        ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.991     0.989     0.990     14252\n",
      "         1.0      0.849     0.873     0.861       968\n",
      "\n",
      "    accuracy                          0.982     15220\n",
      "   macro avg      0.920     0.931     0.926     15220\n",
      "weighted avg      0.982     0.982     0.982     15220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Classifier\n",
    "xgb_params = {'max_depth': 17, 'min_child_weight': 1}\n",
    "model = xgb(**xgb_params)\n",
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_test)\n",
    "print('XGBoost Classifier:')\n",
    "print(classification_report(y_test, preds, digits= 3))\n",
    "results = results.append({'Model name':'XGBoost',\n",
    "                          'Feature_Engineered_data(Y/N)':'Y',\n",
    "                          'F1-score(weighted)':f1_score(y_test, preds, average = 'weighted'),\n",
    "                          'Accuracy':accuracy_score(y_test, preds)},\n",
    "                        ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.989     0.930     0.959     14252\n",
      "         1.0      0.451     0.843     0.588       968\n",
      "\n",
      "    accuracy                          0.925     15220\n",
      "   macro avg      0.720     0.887     0.773     15220\n",
      "weighted avg      0.954     0.925     0.935     15220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adaboost Classifier\n",
    "model = adaboost()\n",
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_test)\n",
    "print('Adaboost Classifier:')\n",
    "print(classification_report(y_test, preds, digits= 3))\n",
    "results = results.append({'Model name':'Adaboost',\n",
    "                          'Feature_Engineered_data(Y/N)':'Y',\n",
    "                          'F1-score(weighted)':f1_score(y_test, preds, average = 'weighted'),\n",
    "                          'Accuracy':accuracy_score(y_test, preds)},\n",
    "                        ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.992     0.980     0.986     14252\n",
      "         1.0      0.751     0.886     0.813       968\n",
      "\n",
      "    accuracy                          0.974     15220\n",
      "   macro avg      0.871     0.933     0.899     15220\n",
      "weighted avg      0.977     0.974     0.975     15220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# trying out the LightGBM classifier\n",
    "model = lightgbm()\n",
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_test)\n",
    "print('LightGBM Classifier:')\n",
    "print(classification_report(y_test, preds, digits= 3))\n",
    "results = results.append({'Model name':'LightGBM',\n",
    "                          'Feature_Engineered_data(Y/N)':'Y',\n",
    "                          'F1-score(weighted)':f1_score(y_test, preds, average = 'weighted'),\n",
    "                          'Accuracy':accuracy_score(y_test, preds)},\n",
    "                        ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ensembles of classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft Voting Classifier with ET and catboost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.992     0.991     0.991     14252\n",
      "         1.0      0.872     0.875     0.874       968\n",
      "\n",
      "    accuracy                          0.984     15220\n",
      "   macro avg      0.932     0.933     0.933     15220\n",
      "weighted avg      0.984     0.984     0.984     15220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A soft voting ensemble with ET and catboost, our previously top performing algorithms\n",
    "model1 = ExtraTreesClassifier()\n",
    "model2 = catboost(**cat_params)\n",
    "model = VotingClassifier(estimators = [('et', model1), ('ctboost',model2)], verbose=False, voting = 'soft')\n",
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_test)\n",
    "print('Soft Voting Classifier with ET and catboost:')\n",
    "print(classification_report(y_test, preds, digits= 3))\n",
    "results = results.append({'Model name':'Soft Voting Ensemble: ET & Catboost',\n",
    "                          'Feature_Engineered_data(Y/N)':'Y',\n",
    "                          'F1-score(weighted)':f1_score(y_test, preds, average = 'weighted'),\n",
    "                          'Accuracy':accuracy_score(y_test, preds)},\n",
    "                        ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft Voting Classifier with ET, catboost and xgboost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.991     0.991     0.991     14252\n",
      "         1.0      0.864     0.874     0.869       968\n",
      "\n",
      "    accuracy                          0.983     15220\n",
      "   macro avg      0.928     0.932     0.930     15220\n",
      "weighted avg      0.983     0.983     0.983     15220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Soft Voting Classifier with ET, catboost and xgboost:\n",
    "model1 = ExtraTreesClassifier()\n",
    "model2 = catboost(**cat_params)\n",
    "model3 = xgb(**xgb_params)\n",
    "model = VotingClassifier(estimators = [('et', model1), ('ctboost',model2), ('xgb', model3)], voting = 'soft', verbose=0)\n",
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_test)\n",
    "print('Soft Voting Classifier with ET, catboost and xgboost:')\n",
    "print(classification_report(y_test, preds, digits= 3))\n",
    "results = results.append({'Model name':'Soft Voting Ensemble: ET, Catboost & XGB',\n",
    "                          'Feature_Engineered_data(Y/N)':'Y',\n",
    "                          'F1-score(weighted)':f1_score(y_test, preds, average = 'weighted'),\n",
    "                          'Accuracy':accuracy_score(y_test, preds)},\n",
    "                        ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Classifier with ET, catboost and XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.991     0.991     0.991     14252\n",
      "         1.0      0.867     0.874     0.870       968\n",
      "\n",
      "    accuracy                          0.983     15220\n",
      "   macro avg      0.929     0.932     0.931     15220\n",
      "weighted avg      0.984     0.983     0.983     15220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hard Voting Classifier with ET, catboost and XGBoost\n",
    "model1 = ExtraTreesClassifier()\n",
    "model2 = catboost(**cat_params)\n",
    "model3 = xgb(**xgb_params)\n",
    "model = VotingClassifier(estimators = [('et', model1), ('ctboost',model2), ('xgb', model3)], voting = 'hard', verbose=0)\n",
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_test)\n",
    "print('Hard Voting Classifier with ET, catboost and XGBoost')\n",
    "print(classification_report(y_test, preds, digits= 3))\n",
    "results = results.append({'Model name':'Hard Voting Ensemble: ET, Catboost and XGB',\n",
    "                          'Feature_Engineered_data(Y/N)':'Y',\n",
    "                          'F1-score(weighted)':f1_score(y_test, preds, average = 'weighted'),\n",
    "                          'Accuracy':accuracy_score(y_test, preds)},\n",
    "                        ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier with ET and catboost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.991     0.991     0.991     14252\n",
      "         1.0      0.869     0.872     0.871       968\n",
      "\n",
      "    accuracy                          0.984     15220\n",
      "   macro avg      0.930     0.931     0.931     15220\n",
      "weighted avg      0.984     0.984     0.984     15220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stacking Classifier with ET and catboost\n",
    "model1 = ExtraTreesClassifier()\n",
    "model2 = catboost(**cat_params)\n",
    "model = StackingClassifier(estimators = [('et', model1), ('ctboost',model2)], verbose=0, final_estimator=LogisticRegression())\n",
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_test)\n",
    "print('Stacking Classifier with ET and catboost')\n",
    "print(classification_report(y_test, preds, digits= 3))\n",
    "results = results.append({'Model name':'Stacking Ensemble: ET & catboost',\n",
    "                          'Feature_Engineered_data(Y/N)':'Y',\n",
    "                          'F1-score(weighted)':f1_score(y_test, preds, average = 'weighted'),\n",
    "                          'Accuracy':accuracy_score(y_test, preds)},\n",
    "                        ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier with ET, catboost and XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.991     0.992     0.992     14252\n",
      "         1.0      0.877     0.872     0.875       968\n",
      "\n",
      "    accuracy                          0.984     15220\n",
      "   macro avg      0.934     0.932     0.933     15220\n",
      "weighted avg      0.984     0.984     0.984     15220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stacking Classifier with ET, catboost and XGBoost\n",
    "model1 = ExtraTreesClassifier(n_jobs = -1)\n",
    "model2 = catboost(**cat_params)\n",
    "model3 = xgb(**xgb_params)\n",
    "model = StackingClassifier(estimators = [('et', model1), \n",
    "                                         ('ctboost',model2), \n",
    "                                         ('xgb', model3)], \n",
    "                           verbose=0, final_estimator=LogisticRegression(), n_jobs = -1)\n",
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_test)\n",
    "print('Stacking Classifier with ET, catboost and XGBoost')\n",
    "print(classification_report(y_test, preds, digits= 3))\n",
    "results = results.append({'Model name':'Stacking Ensemble: ET, catboost & XGB',\n",
    "                          'Feature_Engineered_data(Y/N)':'Y',\n",
    "                          'F1-score(weighted)':f1_score(y_test, preds, average = 'weighted'),\n",
    "                          'Accuracy':accuracy_score(y_test, preds)},\n",
    "                        ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model name</th>\n",
       "      <th>Feature_Engineered_data(Y/N)</th>\n",
       "      <th>F1-score(weighted)</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>N</td>\n",
       "      <td>0.982834</td>\n",
       "      <td>0.982917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Catboost</td>\n",
       "      <td>N</td>\n",
       "      <td>0.983484</td>\n",
       "      <td>0.983377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>N</td>\n",
       "      <td>0.981908</td>\n",
       "      <td>0.981800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>N</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.917017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.981901</td>\n",
       "      <td>0.981997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Catboost</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.983268</td>\n",
       "      <td>0.983180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.982178</td>\n",
       "      <td>0.982063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.935067</td>\n",
       "      <td>0.924836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.975043</td>\n",
       "      <td>0.974047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Soft Voting Ensemble: ET &amp; Catboost</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.983914</td>\n",
       "      <td>0.983903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Soft Voting Ensemble: ET, Catboost &amp; XGB</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.983290</td>\n",
       "      <td>0.983246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hard Voting Ensemble: ET, Catboost and XGB</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.983475</td>\n",
       "      <td>0.983443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Stacking Ensemble: ET &amp; catboost</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.983520</td>\n",
       "      <td>0.983509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Stacking Ensemble: ET, catboost &amp; XGB</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.984077</td>\n",
       "      <td>0.984100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Model name Feature_Engineered_data(Y/N)  \\\n",
       "0                                  Extra Trees                            N   \n",
       "1                                     Catboost                            N   \n",
       "2                                      XGBoost                            N   \n",
       "3                                     Adaboost                            N   \n",
       "4                                  Extra Trees                            Y   \n",
       "5                                     Catboost                            Y   \n",
       "6                                      XGBoost                            Y   \n",
       "7                                     Adaboost                            Y   \n",
       "8                                     LightGBM                            Y   \n",
       "9          Soft Voting Ensemble: ET & Catboost                            Y   \n",
       "10    Soft Voting Ensemble: ET, Catboost & XGB                            Y   \n",
       "11  Hard Voting Ensemble: ET, Catboost and XGB                            Y   \n",
       "12            Stacking Ensemble: ET & catboost                            Y   \n",
       "13       Stacking Ensemble: ET, catboost & XGB                            Y   \n",
       "\n",
       "    F1-score(weighted)  Accuracy  \n",
       "0             0.982834  0.982917  \n",
       "1             0.983484  0.983377  \n",
       "2             0.981908  0.981800  \n",
       "3             0.929381  0.917017  \n",
       "4             0.981901  0.981997  \n",
       "5             0.983268  0.983180  \n",
       "6             0.982178  0.982063  \n",
       "7             0.935067  0.924836  \n",
       "8             0.975043  0.974047  \n",
       "9             0.983914  0.983903  \n",
       "10            0.983290  0.983246  \n",
       "11            0.983475  0.983443  \n",
       "12            0.983520  0.983509  \n",
       "13            0.984077  0.984100  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The summarised results of various classifiers and ensembles\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of f1-score and accuracy the 'Stacking Ensemble: ET, catboost & XGB' is leading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRID SEARCH: <br>The following optimization for model creation have been been used for comparison and not for evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.982260 using {'max_depth': 19, 'min_child_weight': 1}\n",
      "Test : 0.981326 with: {'max_depth': 13, 'min_child_weight': 1}\n",
      "Test : 0.979642 with: {'max_depth': 13, 'min_child_weight': 3}\n",
      "Test : 0.978532 with: {'max_depth': 13, 'min_child_weight': 5}\n",
      "Test : 0.981700 with: {'max_depth': 15, 'min_child_weight': 1}\n",
      "Test : 0.980090 with: {'max_depth': 15, 'min_child_weight': 3}\n",
      "Test : 0.979061 with: {'max_depth': 15, 'min_child_weight': 5}\n",
      "Test : 0.982249 with: {'max_depth': 17, 'min_child_weight': 1}\n",
      "Test : 0.980841 with: {'max_depth': 17, 'min_child_weight': 3}\n",
      "Test : 0.979615 with: {'max_depth': 17, 'min_child_weight': 5}\n",
      "Test : 0.982260 with: {'max_depth': 19, 'min_child_weight': 1}\n",
      "Test : 0.981159 with: {'max_depth': 19, 'min_child_weight': 3}\n",
      "Test : 0.980027 with: {'max_depth': 19, 'min_child_weight': 5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=19,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search on xgboost models\n",
    "model = xgb()\n",
    "# initial grid search parameters\n",
    "grid = {'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "        }\n",
    "# updated grid search parameters based on previous results ()\n",
    "grid = {'max_depth':range(9,14,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "        }\n",
    "grid = {'max_depth':range(13,20,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "        }\n",
    "\n",
    "gsc = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=grid,\n",
    "    scoring='f1_weighted',\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "grid_result = gsc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "for test_mean, param in zip(\n",
    "        grid_result.cv_results_['mean_test_score'],\n",
    "        grid_result.cv_results_['params']):\n",
    "    print(\"Test : %f with: %r\" % (test_mean, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose 'max_depth' of xgb() to be 17 due to the negligible increase in score. 'min_child_weight' can be set to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.941526 using {'depth': 12, 'iterations': 1500}\n",
      "Test : 0.939062 with: {'depth': 12, 'iterations': 500}\n",
      "Test : 0.940189 with: {'depth': 12, 'iterations': 1000}\n",
      "Test : 0.941526 with: {'depth': 12, 'iterations': 1500}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x248b7cfda88>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search on catboost models\n",
    "model = catboost(verbose = False)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# initial grid search parameters\n",
    "grid = {'depth'         : [6,8,10],\n",
    "          'learning_rate' : [0.01, 0.05, 0.1],\n",
    "          'iterations'    : [30, 50, 100]\n",
    "         }\n",
    "# updated parameters based on previous results\n",
    "grid = {'depth'         : [10,20,30],\n",
    "          'learning_rate' : [0.1, 0.15, 0.2],\n",
    "          'iterations'    : [100, 150, 200]\n",
    "         }\n",
    "grid = {'depth'         : [10, 12],\n",
    "          'learning_rate' : [0.2,0.25,0.3],\n",
    "          'iterations'    : [200, 275, 350]\n",
    "         }\n",
    "grid = {'depth'         : [12],\n",
    "          'learning_rate' : [0.25],\n",
    "          'iterations'    : [350,400,500]\n",
    "         }\n",
    "# set learning rate to automatically set\n",
    "grid = {'depth'         : [12],\n",
    "          'iterations'    : [500,1000,1500]\n",
    "         }\n",
    "\n",
    "gsc = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=grid,\n",
    "    scoring='f1_weighted',\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "grid_result = gsc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "for test_mean, param in zip(\n",
    "        grid_result.cv_results_['mean_test_score'],\n",
    "        grid_result.cv_results_['params']):\n",
    "    print(\"Test : %f with: %r\" % (test_mean, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is seen that an increase in the number of iterations is only increasing the scores by minute amounts. Let the default iterations be used (1000). The depth (max = 16 for the data) can be chosen from [6,8,10] as depth greater than 10 is computationally very expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.982351 using {'depth': 10}\n",
      "Test : 0.972020 with: {'depth': 6}\n",
      "Test : 0.978821 with: {'depth': 8}\n",
      "Test : 0.982351 with: {'depth': 10}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1b0328535c8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search on catboost models using f1-scores\n",
    "model = catboost(verbose = False)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# initial grid search parameters\n",
    "grid = {'depth' : [6,8,10]\n",
    "         }\n",
    "\n",
    "gsc = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=grid,\n",
    "    scoring='f1_weighted',\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "grid_result = gsc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "for test_mean, param in zip(\n",
    "        grid_result.cv_results_['mean_test_score'],\n",
    "        grid_result.cv_results_['params']):\n",
    "    print(\"Test : %f with: %r\" % (test_mean, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.985251 using {'max_features': 12, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Test : 0.984467 with: {'max_features': 7, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Test : 0.984657 with: {'max_features': 8, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Test : 0.984626 with: {'max_features': 9, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Test : 0.984912 with: {'max_features': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Test : 0.985165 with: {'max_features': 11, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Test : 0.985251 with: {'max_features': 12, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(max_features=12, n_jobs=-1)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search on catboost models\n",
    "model = ExtraTreesClassifier(n_jobs=-1)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#inital grid search parameters\n",
    "grid = {'n_estimators': range(50,126,25),\n",
    "        'max_features': range(3,12,3),\n",
    "        'min_samples_leaf': range(1,2,3),\n",
    "        'min_samples_split': range(2,3,4)}\n",
    "# updated parameters\n",
    "grid = {'n_estimators': [100],\n",
    "        'max_features': [7,8,9,10,11,12],\n",
    "        'min_samples_leaf': [1],\n",
    "        'min_samples_split': [2]}\n",
    "\n",
    "\n",
    "gsc = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=grid,\n",
    "    scoring='f1_weighted',\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "grid_result = gsc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "for test_mean, param in zip(\n",
    "        grid_result.cv_results_['mean_test_score'],\n",
    "        grid_result.cv_results_['params']):\n",
    "    print(\"Test : %f with: %r\" % (test_mean, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose the max features 12 (full) and min_samples_leaf and min_samples_split are seen to be default values (1 and 2). The best n_estimators also is seen to be the default value (100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.946877 using {'max_features': 12, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Test : 0.944695 with: {'max_features': 7, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Test : 0.945540 with: {'max_features': 8, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Test : 0.946068 with: {'max_features': 9, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Test : 0.945962 with: {'max_features': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Test : 0.946420 with: {'max_features': 11, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Test : 0.946877 with: {'max_features': 12, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(max_features=12, n_jobs=-1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search on catboost models\n",
    "model = ExtraTreesClassifier(n_jobs=-1)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#inital grid search parameters\n",
    "grid = {'n_estimators': range(50,126,25),\n",
    "        'max_features': range(3,12,3),\n",
    "        'min_samples_leaf': range(1,2,3),\n",
    "        'min_samples_split': range(2,3,4)}\n",
    "# updated parameters\n",
    "grid = {'n_estimators': [100],\n",
    "        'max_features': [7,8,9,10,11,12],\n",
    "        'min_samples_leaf': [1],\n",
    "        'min_samples_split': [2]}\n",
    "\n",
    "\n",
    "gsc = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=grid,\n",
    "    scoring='r2',\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "grid_result = gsc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "for test_mean, param in zip(\n",
    "        grid_result.cv_results_['mean_test_score'],\n",
    "        grid_result.cv_results_['params']):\n",
    "    print(\"Test : %f with: %r\" % (test_mean, param))\n",
    "    \n",
    "model = ExtraTreesClassifier(**grid_result.best_params_, n_jobs=-1)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "names = (['ID', 'Expense', 'Income', 'Loan type', 'Occupation type', \n",
    "         'Age', 'Score1', 'Score2', 'Score3', 'Score4', 'Score5'])\n",
    "\n",
    "X_test = pd.read_csv('dataset/test_x.csv', index_col = 'ID', names = names, skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using full data\n",
    "X_train = X.copy()\n",
    "y_train = y.copy()\n",
    "\n",
    "# we use smote categorical oversampling\n",
    "oversampler = SMOTENC(random_state= 42, categorical_features=[2,3,4], sampling_strategy=2/3)\n",
    "X_train, y_train = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# reset index name as smote removes the index name\n",
    "X_train.index.name = 'ID'\n",
    "\n",
    "# the feature engineering function from feature_engineer.py on train data\n",
    "X_train, X_train_bins = feature_engineer(X_train.reset_index(), False)\n",
    "\n",
    "# creating dummy variables for Occupation type\n",
    "X_train, y_train = dummy_creator(X_train, y_train)\n",
    "\n",
    "# This conversion is done so that catboost may consider these features \n",
    "# as categorical features as they are already one-hot encoded (two categories)\n",
    "X_train['Loan type'] = X_train['Loan type'].astype(int)\n",
    "X_train.Age = X_train.Age.astype(int)\n",
    "X_train['Age X Loan type'] = X_train['Age X Loan type'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joe\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# encoding the occupation and loan types\n",
    "X_test = ManualEncoder(X_test)\n",
    "# applying the above operations on x_test\n",
    "X_test, temp = basic_clean(X_test, pd.DataFrame(np.ones(len(X_test))), non_cat_cols_X)\n",
    "X_test.index.name = 'ID'\n",
    "X_test, X_test_bins = feature_engineer(X_test.reset_index(), False)\n",
    "X_test, temp = dummy_creator(X_test, np.ones(len(X_test)))\n",
    "X_test['Loan type'] = X_test['Loan type'].astype(int)\n",
    "X_test.Age = X_test.Age.astype(int)\n",
    "X_test['Age X Loan type'] = X_test['Age X Loan type'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking Classifier with ET, catboost and XGBoost\n",
    "model1 = ExtraTreesClassifier(n_jobs = -1)\n",
    "model2 = catboost(depth = 10, task_type = 'GPU', verbose = 0)\n",
    "model3 = xgb(max_depth= 17, min_child_weight= 1)\n",
    "model = StackingClassifier(estimators = [('et', model1), \n",
    "                                         ('ctboost',model2), \n",
    "                                         ('xgb', model3)], \n",
    "                           verbose=0, final_estimator=LogisticRegression())\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label\n",
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        0.0\n",
       "4        0.0\n",
       "...      ...\n",
       "19995    0.0\n",
       "19996    1.0\n",
       "19997    1.0\n",
       "19998    0.0\n",
       "19999    0.0\n",
       "\n",
       "[20000 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting predictions to dataframe for saving\n",
    "preds = model.predict(X_test)\n",
    "preds = pd.DataFrame(preds, columns = ['Label'])\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the data\n",
    "preds.to_csv('ML_predictions.csv')\n",
    "# Save to file in the current working directory\n",
    "pkl_filename = \"stacking_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_probs = model.predict_proba(X_test)\n",
    "preds_probs = pd.DataFrame(preds_probs[:,1], columns = ['Label'])\n",
    "preds_probs.to_csv('ML_prob_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0.009630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0.590222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0.987349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0.012569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0.004713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Label\n",
       "0      0.004333\n",
       "1      0.005319\n",
       "2      0.005317\n",
       "3      0.004333\n",
       "4      0.004334\n",
       "...         ...\n",
       "19995  0.009630\n",
       "19996  0.590222\n",
       "19997  0.987349\n",
       "19998  0.012569\n",
       "19999  0.004713\n",
       "\n",
       "[20000 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predictor(model_filename, X_test_filename):\n",
    "    # reading X_test\n",
    "    # read data\n",
    "    names = (['ID', 'Expense', 'Income', 'Loan type', 'Occupation type', \n",
    "             'Age', 'Score1', 'Score2', 'Score3', 'Score4', 'Score5'])\n",
    "\n",
    "    X_test = pd.read_csv(X_test_filename, index_col = 'ID', names = names, skiprows = 1)\n",
    "    # X_test_prepreocessing\n",
    "    # encoding the occupation and loan types\n",
    "    X_test = ManualEncoder(X_test)\n",
    "    # applying the above operations on x_test\n",
    "    X_test, temp = basic_clean(X_test, pd.DataFrame(np.ones(len(X_test))), non_cat_cols_X)\n",
    "    X_test.index.name = 'ID'\n",
    "    X_test, X_test_bins = feature_engineer(X_test.reset_index(), False)\n",
    "    X_test, temp = dummy_creator(X_test, np.ones(len(X_test)))\n",
    "    X_test['Loan type'] = X_test['Loan type'].astype(int)\n",
    "    X_test.Age = X_test.Age.astype(int)\n",
    "    X_test['Age X Loan type'] = X_test['Age X Loan type'].astype(int)\n",
    "    pkl_filename = model_filename\n",
    "    # Load from file\n",
    "    with open(pkl_filename, 'rb') as file:\n",
    "        pickle_model = pickle.load(file)\n",
    "\n",
    "    # predict target values\n",
    "    return pickle_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joe\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "model_filename = \"stacking_model.pkl\"\n",
    "X_test_filename = 'dataset/test_x.csv'\n",
    "y_preds = test_predictor(model_filename, X_test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictor(model_filename, 'RF_imputed_X.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
